----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
Iteration:500  Loss:tensor(1.5227, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(51, device='cuda:0')
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
Iteration:500  Loss:tensor(1.0402, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(82, device='cuda:0')
Iteration:1000  Loss:tensor(0.7432, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(84, device='cuda:0')
echo: 0
loss: 0.8506967199592605
accuracy: 0.6977907780410743
Iteration:1500  Loss:tensor(0.5699, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:2000  Loss:tensor(0.7436, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:2500  Loss:tensor(0.5748, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 1
loss: 0.6299759727000813
accuracy: 0.7651930292259084
Iteration:3000  Loss:tensor(0.5300, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:3500  Loss:tensor(0.5540, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 2
loss: 0.546463354857047
accuracy: 0.7967725612164297
Iteration:4000  Loss:tensor(0.3490, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:4500  Loss:tensor(0.5254, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:5000  Loss:tensor(0.4335, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 3
loss: 0.47710152773118886
accuracy: 0.8185303120063192
Iteration:5500  Loss:tensor(0.4892, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:6000  Loss:tensor(0.3780, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 4
loss: 0.4413357188374887
accuracy: 0.8314277251184835
Iteration:6500  Loss:tensor(0.3176, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:7000  Loss:tensor(0.4979, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:7500  Loss:tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 5
loss: 0.42268922545992743
accuracy: 0.8379134577409163
Iteration:8000  Loss:tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:8500  Loss:tensor(0.2897, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 6
loss: 0.39782493660376533
accuracy: 0.844339948657188
Iteration:9000  Loss:tensor(0.4445, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:9500  Loss:tensor(0.2944, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:10000  Loss:tensor(0.3549, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 7
loss: 0.35712115847951426
accuracy: 0.8575273992890996
Iteration:10500  Loss:tensor(0.4246, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:11000  Loss:tensor(0.3429, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 8
loss: 0.344407576779242
accuracy: 0.8621001184834124
Iteration:11500  Loss:tensor(0.2753, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:12000  Loss:tensor(0.4423, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:12500  Loss:tensor(0.4975, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 9
loss: 0.35998059357229567
accuracy: 0.8561389218009479
Iteration:13000  Loss:tensor(0.2355, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:13500  Loss:tensor(0.2567, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 10
loss: 0.324146857676442
accuracy: 0.8684562598736177
Iteration:14000  Loss:tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:14500  Loss:tensor(0.4193, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:15000  Loss:tensor(0.4608, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 11
loss: 0.47057813972140566
accuracy: 0.8304082740916272
Iteration:15500  Loss:tensor(0.3208, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:16000  Loss:tensor(0.2939, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 12
loss: 0.3508109370067033
accuracy: 0.8597539000789889
Iteration:16500  Loss:tensor(0.4530, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:17000  Loss:tensor(0.3246, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:17500  Loss:tensor(0.3233, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 13
loss: 0.31715930984201024
accuracy: 0.870451964849921
Iteration:18000  Loss:tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:18500  Loss:tensor(0.3814, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 14
loss: 0.3766471457213022
accuracy: 0.855572422985782
Iteration:19000  Loss:tensor(0.3279, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:19500  Loss:tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:20000  Loss:tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 15
loss: 0.29614303062124087
accuracy: 0.8839948657187994
Iteration:20500  Loss:tensor(0.3477, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(83, device='cuda:0')
Iteration:21000  Loss:tensor(0.2669, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:21500  Loss:tensor(0.2914, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 16
loss: 0.37550175776131345
accuracy: 0.8662470379146919
Iteration:22000  Loss:tensor(0.2479, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:22500  Loss:tensor(0.2363, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 17
loss: 0.2512059164649879
accuracy: 0.8991459320695102
Iteration:23000  Loss:tensor(0.2996, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:23500  Loss:tensor(0.2604, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:24000  Loss:tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 18
loss: 0.24710845578267676
accuracy: 0.9006677033965245
Iteration:24500  Loss:tensor(0.2553, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:25000  Loss:tensor(0.2185, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 19
loss: 0.259210276048142
accuracy: 0.898741113744076
Iteration:25500  Loss:tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:26000  Loss:tensor(0.3205, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:26500  Loss:tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 20
loss: 0.25547242574805706
accuracy: 0.9008787519747236
Iteration:27000  Loss:tensor(0.2560, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:27500  Loss:tensor(0.1861, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 21
loss: 0.2358438193350795
accuracy: 0.9067510860979464
Iteration:28000  Loss:tensor(0.2890, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:28500  Loss:tensor(0.2799, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:29000  Loss:tensor(0.4043, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 22
loss: 0.2436272687091835
accuracy: 0.9037433353080568
Iteration:29500  Loss:tensor(0.2245, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:30000  Loss:tensor(0.1859, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 23
loss: 0.2303847016598941
accuracy: 0.9072250197472354
Iteration:30500  Loss:tensor(0.2621, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:31000  Loss:tensor(0.2247, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:31500  Loss:tensor(0.2529, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 24
loss: 0.2468538934138337
accuracy: 0.9029361670616114
Iteration:32000  Loss:tensor(0.1783, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:32500  Loss:tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 25
loss: 0.21937679861323528
accuracy: 0.9112349427330173
Iteration:33000  Loss:tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:33500  Loss:tensor(0.1999, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:34000  Loss:tensor(0.1628, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 26
loss: 0.21935459781338065
accuracy: 0.9125740521327014
Iteration:34500  Loss:tensor(0.2533, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:35000  Loss:tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 27
loss: 0.2256250714803759
accuracy: 0.9105869865718799
Iteration:35500  Loss:tensor(0.1736, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:36000  Loss:tensor(0.2137, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:36500  Loss:tensor(0.3219, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 28
loss: 0.2745622816373481
accuracy: 0.8983091429699843
Iteration:37000  Loss:tensor(0.2621, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:37500  Loss:tensor(0.2051, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 29
loss: 0.2486757406020334
accuracy: 0.9044147413112165
Iteration:38000  Loss:tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:38500  Loss:tensor(0.1908, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:39000  Loss:tensor(0.1616, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 30
loss: 0.21477628031401272
accuracy: 0.9161211492890996
Iteration:39500  Loss:tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:40000  Loss:tensor(0.2425, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:40500  Loss:tensor(0.2849, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 31
loss: 0.21310457985665748
accuracy: 0.9151041666666666
Iteration:41000  Loss:tensor(0.5658, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:41500  Loss:tensor(0.3043, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 32
loss: 0.35715823521687523
accuracy: 0.876115718799368
Iteration:42000  Loss:tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:42500  Loss:tensor(0.3156, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:43000  Loss:tensor(0.2459, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 33
loss: 0.234991768654583
accuracy: 0.9080938981042653
Iteration:43500  Loss:tensor(0.1879, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:44000  Loss:tensor(0.1456, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 34
loss: 0.22528597703689082
accuracy: 0.9124703791469194
Iteration:44500  Loss:tensor(0.2108, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:45000  Loss:tensor(0.2429, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:45500  Loss:tensor(0.3645, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 35
loss: 0.21058279750236025
accuracy: 0.9157743384676145
Iteration:46000  Loss:tensor(0.1337, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:46500  Loss:tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 36
loss: 0.2213429470574498
accuracy: 0.9127110485781991
Iteration:47000  Loss:tensor(0.2503, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:47500  Loss:tensor(0.1478, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:48000  Loss:tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 37
loss: 0.2559448317175887
accuracy: 0.9058279028436019
Iteration:48500  Loss:tensor(0.2912, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:49000  Loss:tensor(0.2322, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 38
loss: 0.2189557168332604
accuracy: 0.9157607622432861
Iteration:49500  Loss:tensor(0.2587, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:50000  Loss:tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:50500  Loss:tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 39
loss: 0.21526594738377403
accuracy: 0.915836048578199
Iteration:51000  Loss:tensor(0.2357, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:51500  Loss:tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 40
loss: 0.2047093479377681
accuracy: 0.91761823657188
Iteration:52000  Loss:tensor(0.1675, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:52500  Loss:tensor(0.1385, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:53000  Loss:tensor(0.3017, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 41
loss: 0.22367279882444213
accuracy: 0.9135823953396526
Iteration:53500  Loss:tensor(0.2758, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:54000  Loss:tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 42
loss: 0.20905087446855708
accuracy: 0.9173812697472353
Iteration:54500  Loss:tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:55000  Loss:tensor(0.1166, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:55500  Loss:tensor(0.1578, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 43
loss: 0.26270144094387876
accuracy: 0.9036828593996841
Iteration:56000  Loss:tensor(0.1930, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:56500  Loss:tensor(0.1896, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 44
loss: 0.23664251506905326
accuracy: 0.9129973834913112
Iteration:57000  Loss:tensor(0.1629, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:57500  Loss:tensor(0.2189, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:58000  Loss:tensor(0.1727, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 45
loss: 0.20314018641956044
accuracy: 0.9197521721958926
Iteration:58500  Loss:tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:59000  Loss:tensor(0.2738, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:59500  Loss:tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 46
loss: 0.20294643481854954
accuracy: 0.9205605746445498
Iteration:60000  Loss:tensor(0.2834, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:60500  Loss:tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 47
loss: 0.29689972356291366
accuracy: 0.8981610387045814
Iteration:61000  Loss:tensor(0.2832, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:61500  Loss:tensor(0.2664, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:62000  Loss:tensor(0.2006, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 48
loss: 0.24265113088639237
accuracy: 0.9076495853080568
Iteration:62500  Loss:tensor(0.2309, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:63000  Loss:tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 49
loss: 0.20096795430103845
accuracy: 0.9200977488151659
Iteration:63500  Loss:tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:64000  Loss:tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:64500  Loss:tensor(0.1931, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 50
loss: 0.20604986849566112
accuracy: 0.9198595477883096
Iteration:65000  Loss:tensor(0.1516, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:65500  Loss:tensor(0.2037, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 51
loss: 0.2201501010589031
accuracy: 0.9151140402843602
Iteration:66000  Loss:tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:66500  Loss:tensor(0.2354, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:67000  Loss:tensor(0.2470, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 52
loss: 0.21360353581713273
accuracy: 0.9158755430489731
Iteration:67500  Loss:tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:68000  Loss:tensor(0.1328, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 53
loss: 0.20624732635738727
accuracy: 0.9187586394154819
Iteration:68500  Loss:tensor(0.1623, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:69000  Loss:tensor(0.2142, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:69500  Loss:tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 54
loss: 0.20575796539113986
accuracy: 0.9183390106635071
Iteration:70000  Loss:tensor(0.2098, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:70500  Loss:tensor(0.2736, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 55
loss: 0.20773283372769988
accuracy: 0.9174084221958927
Iteration:71000  Loss:tensor(0.1727, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:71500  Loss:tensor(0.2115, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:72000  Loss:tensor(0.2745, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 56
loss: 0.2142325630190813
accuracy: 0.9158928218799368
Iteration:72500  Loss:tensor(0.1927, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:73000  Loss:tensor(0.2488, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 57
loss: 0.20302461257489843
accuracy: 0.9189919036334913
Iteration:73500  Loss:tensor(0.2590, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:74000  Loss:tensor(0.1725, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:74500  Loss:tensor(0.2413, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 58
loss: 0.2058133123174757
accuracy: 0.91848711492891
Iteration:75000  Loss:tensor(0.1712, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:75500  Loss:tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 59
loss: 0.20777059847850934
accuracy: 0.9194053613744075
Iteration:76000  Loss:tensor(0.1866, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:76500  Loss:tensor(0.1705, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:77000  Loss:tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 60
loss: 0.20874641080038242
accuracy: 0.9201249012638231
Iteration:77500  Loss:tensor(0.2562, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:78000  Loss:tensor(0.5427, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(81, device='cuda:0')
echo: 61
loss: 0.45787735711812594
accuracy: 0.8690313981042653
Iteration:78500  Loss:tensor(0.4788, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:79000  Loss:tensor(0.2567, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:79500  Loss:tensor(0.4498, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 62
loss: 0.3093743876835087
accuracy: 0.8875185130331754
Iteration:80000  Loss:tensor(0.2716, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:80500  Loss:tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:81000  Loss:tensor(0.2171, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 63
loss: 0.2144925031769803
accuracy: 0.9159545319905213
Iteration:81500  Loss:tensor(0.2895, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:82000  Loss:tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 64
loss: 0.19555616892556443
accuracy: 0.9232597748815166
Iteration:82500  Loss:tensor(0.1653, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:83000  Loss:tensor(0.2174, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:83500  Loss:tensor(0.2023, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 65
loss: 0.20151304327963748
accuracy: 0.9223230154028437
Iteration:84000  Loss:tensor(0.1780, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:84500  Loss:tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 66
loss: 0.19570186258680636
accuracy: 0.9228278041074249
Iteration:85000  Loss:tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:85500  Loss:tensor(0.2002, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:86000  Loss:tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 67
loss: 0.20052670903421502
accuracy: 0.9212122334123223
Iteration:86500  Loss:tensor(0.4256, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:87000  Loss:tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 68
loss: 0.2230734901641029
accuracy: 0.9157644648499209
Iteration:87500  Loss:tensor(0.1537, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:88000  Loss:tensor(0.1525, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:88500  Loss:tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 69
loss: 0.19184465470060258
accuracy: 0.9235127863349131
Iteration:89000  Loss:tensor(0.1186, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:89500  Loss:tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 70
loss: 0.19199886661770313
accuracy: 0.924059537914692
Iteration:90000  Loss:tensor(0.3091, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:90500  Loss:tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:91000  Loss:tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 71
loss: 0.19862934085430128
accuracy: 0.921576323064771
Iteration:91500  Loss:tensor(0.1805, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:92000  Loss:tensor(0.1006, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 72
loss: 0.19789555359861297
accuracy: 0.9209086196682464
Iteration:92500  Loss:tensor(0.1642, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:93000  Loss:tensor(0.1864, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:93500  Loss:tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 73
loss: 0.19781153603776183
accuracy: 0.9222452606635071
Iteration:94000  Loss:tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:94500  Loss:tensor(0.2581, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 74
loss: 0.26965127561659236
accuracy: 0.906389464849921
Iteration:95000  Loss:tensor(0.1726, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:95500  Loss:tensor(0.2446, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:96000  Loss:tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 75
loss: 0.2062932415431333
accuracy: 0.9211159656398105
Iteration:96500  Loss:tensor(0.1261, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:97000  Loss:tensor(0.2264, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 76
loss: 0.18633222445774983
accuracy: 0.926782187993681
Iteration:97500  Loss:tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:98000  Loss:tensor(0.1503, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:98500  Loss:tensor(0.2443, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 77
loss: 0.18921148503055035
accuracy: 0.9257479265402844
Iteration:99000  Loss:tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:99500  Loss:tensor(0.1355, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:100000  Loss:tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 78
loss: 0.1901493058414868
accuracy: 0.9244433748025277
Iteration:100500  Loss:tensor(0.1819, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:101000  Loss:tensor(0.1320, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 79
loss: 0.19396606927787619
accuracy: 0.9242816943127962
Iteration:101500  Loss:tensor(0.2245, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:102000  Loss:tensor(0.1759, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:102500  Loss:tensor(0.1749, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 80
loss: 0.20715867935740176
accuracy: 0.9208580173775672
Iteration:103000  Loss:tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:103500  Loss:tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 81
loss: 0.19203140890876075
accuracy: 0.9243557464454977
Iteration:104000  Loss:tensor(0.1999, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:104500  Loss:tensor(0.1645, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:105000  Loss:tensor(0.1905, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 82
loss: 0.1991521898292205
accuracy: 0.9209678613744076
Iteration:105500  Loss:tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:106000  Loss:tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 83
loss: 0.2094800121799747
accuracy: 0.9194288112164297
Iteration:106500  Loss:tensor(0.1940, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:107000  Loss:tensor(0.1911, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:107500  Loss:tensor(0.2254, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 84
loss: 0.18939718934832403
accuracy: 0.9250444312796209
Iteration:108000  Loss:tensor(0.2312, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:108500  Loss:tensor(0.2703, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 85
loss: 0.18882124770379743
accuracy: 0.925489978278041
Iteration:109000  Loss:tensor(0.2977, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:109500  Loss:tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:110000  Loss:tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 86
loss: 0.1901619321656359
accuracy: 0.9254406101895734
Iteration:110500  Loss:tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:111000  Loss:tensor(0.1869, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 87
loss: 0.19390678908352227
accuracy: 0.9236892772511849
Iteration:111500  Loss:tensor(0.2310, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:112000  Loss:tensor(0.1871, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:112500  Loss:tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 88
loss: 0.19355776411073655
accuracy: 0.9243125493680885
Iteration:113000  Loss:tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:113500  Loss:tensor(0.1695, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 89
loss: 0.1919658469657103
accuracy: 0.9248296800947866
Iteration:114000  Loss:tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:114500  Loss:tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:115000  Loss:tensor(0.2549, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 90
loss: 0.19081609506059974
accuracy: 0.9246766390205371
Iteration:115500  Loss:tensor(0.2303, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:116000  Loss:tensor(0.2189, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 91
loss: 0.19738195302762315
accuracy: 0.9224069411532386
Iteration:116500  Loss:tensor(0.2660, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:117000  Loss:tensor(0.1827, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:117500  Loss:tensor(0.1332, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 92
loss: 0.18526153206401527
accuracy: 0.9270240916271721
Iteration:118000  Loss:tensor(0.1584, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:118500  Loss:tensor(0.1245, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:119000  Loss:tensor(0.1325, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 93
loss: 0.24377255438345868
accuracy: 0.9153176836492891
Iteration:119500  Loss:tensor(0.1170, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:120000  Loss:tensor(0.2037, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 94
loss: 0.19012699565757507
accuracy: 0.9260749901263824
Iteration:120500  Loss:tensor(0.1889, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:121000  Loss:tensor(0.1137, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:121500  Loss:tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 95
loss: 0.23563881485618499
accuracy: 0.9150498617693523
Iteration:122000  Loss:tensor(0.1526, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:122500  Loss:tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 96
loss: 0.19198875417594471
accuracy: 0.9255084913112164
Iteration:123000  Loss:tensor(0.2125, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:123500  Loss:tensor(0.2320, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:124000  Loss:tensor(0.2192, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 97
loss: 0.18384062460848788
accuracy: 0.928112657977883
Iteration:124500  Loss:tensor(0.1922, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:125000  Loss:tensor(0.1993, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 98
loss: 0.18575271487377265
accuracy: 0.9273215343601896
Iteration:125500  Loss:tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:126000  Loss:tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:126500  Loss:tensor(0.1973, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 99
loss: 0.18673494542944488
accuracy: 0.9264242693522907
Iteration:127000  Loss:tensor(0.1996, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:127500  Loss:tensor(0.2460, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 100
loss: 0.18901367062382035
accuracy: 0.9254801046603476
Iteration:128000  Loss:tensor(0.1766, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:128500  Loss:tensor(0.1940, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:129000  Loss:tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 101
loss: 0.1905196697979365
accuracy: 0.9251320596366508
Iteration:129500  Loss:tensor(0.2350, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:130000  Loss:tensor(0.1946, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 102
loss: 0.19166540049934558
accuracy: 0.9259355252764613
Iteration:130500  Loss:tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:131000  Loss:tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:131500  Loss:tensor(0.2358, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 103
loss: 0.22877739064136482
accuracy: 0.9175750394944708
Iteration:132000  Loss:tensor(0.2488, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:132500  Loss:tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 104
loss: 0.23301584821482782
accuracy: 0.9137860387045814
Iteration:133000  Loss:tensor(0.1270, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:133500  Loss:tensor(0.2012, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:134000  Loss:tensor(0.2247, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 105
loss: 0.1907989205012766
accuracy: 0.9258009972353871
Iteration:134500  Loss:tensor(0.1592, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:135000  Loss:tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 106
loss: 0.18245549066842637
accuracy: 0.9281780706951026
Iteration:135500  Loss:tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:136000  Loss:tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:136500  Loss:tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 107
loss: 0.18044068031071864
accuracy: 0.9282410150078989
Iteration:137000  Loss:tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:137500  Loss:tensor(0.1529, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 108
loss: 0.18227612617385897
accuracy: 0.9285779522116905
Iteration:138000  Loss:tensor(0.2047, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:138500  Loss:tensor(0.1853, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:139000  Loss:tensor(0.1790, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 109
loss: 0.18486197402562482
accuracy: 0.9276202112954186
Iteration:139500  Loss:tensor(0.2090, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:140000  Loss:tensor(0.1818, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:140500  Loss:tensor(0.3053, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 110
loss: 0.18889239992163664
accuracy: 0.9256862164296998
Iteration:141000  Loss:tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:141500  Loss:tensor(0.1440, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 111
loss: 0.18697343082542386
accuracy: 0.9266920912322275
Iteration:142000  Loss:tensor(0.1611, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:142500  Loss:tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:143000  Loss:tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 112
loss: 0.18356942330114837
accuracy: 0.9279250592417061
Iteration:143500  Loss:tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:144000  Loss:tensor(0.2569, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 113
loss: 0.18522591164738741
accuracy: 0.9277535051342812
Iteration:144500  Loss:tensor(0.1197, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:145000  Loss:tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:145500  Loss:tensor(0.2525, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 114
loss: 0.1845056491905432
accuracy: 0.9279398696682464
Iteration:146000  Loss:tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:146500  Loss:tensor(0.1929, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 115
loss: 0.18181139110377142
accuracy: 0.9293801836492892
Iteration:147000  Loss:tensor(0.2000, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:147500  Loss:tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:148000  Loss:tensor(0.2446, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 116
loss: 0.18460542141014083
accuracy: 0.9293703100315956
Iteration:148500  Loss:tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:149000  Loss:tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 117
loss: 0.178050084263204
accuracy: 0.931923874407583
Iteration:149500  Loss:tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:150000  Loss:tensor(0.1143, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:150500  Loss:tensor(0.1425, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 118
loss: 0.17535653951950078
accuracy: 0.9341281595576619
Iteration:151000  Loss:tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:151500  Loss:tensor(0.1187, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 119
loss: 0.18182771761517671
accuracy: 0.933541913507109
Iteration:152000  Loss:tensor(0.3451, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:152500  Loss:tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:153000  Loss:tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 120
loss: 0.23968502710239395
accuracy: 0.9250999703791469
Iteration:153500  Loss:tensor(0.1858, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:154000  Loss:tensor(0.2241, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 121
loss: 0.17575255967970896
accuracy: 0.9385071090047394
Iteration:154500  Loss:tensor(0.1278, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:155000  Loss:tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:155500  Loss:tensor(0.2762, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
echo: 122
loss: 0.17296147136397272
accuracy: 0.9388131911532385
Iteration:156000  Loss:tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:156500  Loss:tensor(0.1675, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 123
loss: 0.1694916944868427
accuracy: 0.9394080766192734
Iteration:157000  Loss:tensor(0.1097, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(88, device='cuda:0')
Iteration:157500  Loss:tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:158000  Loss:tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 124
loss: 0.16340696928790208
accuracy: 0.9408335801737757
Iteration:158500  Loss:tensor(0.0773, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:159000  Loss:tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:159500  Loss:tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 125
loss: 0.1661691778938258
accuracy: 0.938699644549763
Iteration:160000  Loss:tensor(0.2106, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:160500  Loss:tensor(0.1835, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 126
loss: 0.1644174119378153
accuracy: 0.9394796603475513
Iteration:161000  Loss:tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:161500  Loss:tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:162000  Loss:tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 127
loss: 0.16463310112308646
accuracy: 0.9395574150868878
Iteration:162500  Loss:tensor(0.1119, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:163000  Loss:tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 128
loss: 0.17401484345302198
accuracy: 0.9377801639020537
Iteration:163500  Loss:tensor(0.1579, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:164000  Loss:tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:164500  Loss:tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 129
loss: 0.16402156373830204
accuracy: 0.9418592022116903
Iteration:165000  Loss:tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:165500  Loss:tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 130
loss: 0.16117752764497606
accuracy: 0.9407447176145339
Iteration:166000  Loss:tensor(0.1590, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:166500  Loss:tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:167000  Loss:tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 131
loss: 0.1648233515632708
accuracy: 0.9414074842022118
Iteration:167500  Loss:tensor(0.1466, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:168000  Loss:tensor(0.1225, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 132
loss: 0.16009721326190055
accuracy: 0.9414395734597156
Iteration:168500  Loss:tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:169000  Loss:tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:169500  Loss:tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 133
loss: 0.16134005781163066
accuracy: 0.9421097452606635
Iteration:170000  Loss:tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:170500  Loss:tensor(0.1461, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 134
loss: 0.15992540724304805
accuracy: 0.9406756022906794
Iteration:171000  Loss:tensor(0.1063, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:171500  Loss:tensor(0.1811, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:172000  Loss:tensor(0.1439, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 135
loss: 0.1590628923721741
accuracy: 0.9422887045813586
Iteration:172500  Loss:tensor(0.1937, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:173000  Loss:tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 136
loss: 0.16273263630002596
accuracy: 0.9395290284360189
Iteration:173500  Loss:tensor(0.1700, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:174000  Loss:tensor(0.1659, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:174500  Loss:tensor(0.1193, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 137
loss: 0.15638718474803473
accuracy: 0.9429033372827804
Iteration:175000  Loss:tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:175500  Loss:tensor(0.1539, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 138
loss: 0.15856709346281125
accuracy: 0.9424775375197473
Iteration:176000  Loss:tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:176500  Loss:tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:177000  Loss:tensor(0.3780, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 139
loss: 0.1987854973935356
accuracy: 0.9372284755134281
Iteration:177500  Loss:tensor(0.1566, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:178000  Loss:tensor(0.1129, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:178500  Loss:tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 140
loss: 0.20419084354587735
accuracy: 0.9328236078199053
Iteration:179000  Loss:tensor(0.1090, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:179500  Loss:tensor(0.1364, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 141
loss: 0.18448137903018114
accuracy: 0.936958185229068
Iteration:180000  Loss:tensor(0.1457, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(84, device='cuda:0')
Iteration:180500  Loss:tensor(0.1577, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:181000  Loss:tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 142
loss: 0.2603082443641919
accuracy: 0.922516785150079
Iteration:181500  Loss:tensor(0.1257, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:182000  Loss:tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 143
loss: 0.20860288050290532
accuracy: 0.9281447472353871
Iteration:182500  Loss:tensor(0.1229, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:183000  Loss:tensor(0.2140, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:183500  Loss:tensor(0.1826, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 144
loss: 0.17168196983706047
accuracy: 0.9378998815165877
Iteration:184000  Loss:tensor(0.1859, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:184500  Loss:tensor(0.1868, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 145
loss: 0.15654461176280304
accuracy: 0.9426355154028436
Iteration:185000  Loss:tensor(0.1616, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:185500  Loss:tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:186000  Loss:tensor(0.3883, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 146
loss: 0.15430265713606683
accuracy: 0.9430576125592417
Iteration:186500  Loss:tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:187000  Loss:tensor(0.1127, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 147
loss: 0.15721479963105153
accuracy: 0.9418394549763034
Iteration:187500  Loss:tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:188000  Loss:tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:188500  Loss:tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 148
loss: 0.1610647464939062
accuracy: 0.9412569115323854
Iteration:189000  Loss:tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:189500  Loss:tensor(0.1559, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 149
loss: 0.1590877860522642
accuracy: 0.9415160939968403
Iteration:190000  Loss:tensor(0.1287, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:190500  Loss:tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:191000  Loss:tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 150
loss: 0.15821290263349977
accuracy: 0.9415555884676146
Iteration:191500  Loss:tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:192000  Loss:tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 151
loss: 0.1636590493451598
accuracy: 0.9405916765402843
Iteration:192500  Loss:tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:193000  Loss:tensor(0.1524, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:193500  Loss:tensor(0.1096, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 152
loss: 0.16091231408854137
accuracy: 0.9414938783570301
Iteration:194000  Loss:tensor(0.0749, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:194500  Loss:tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 153
loss: 0.15715397568051756
accuracy: 0.9420937006319114
Iteration:195000  Loss:tensor(0.1924, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:195500  Loss:tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
echo: 0
loss: 1.6258003581756664
accuracy: 0.4177206753554502
echo: 1
loss: 1.0678450750513664
accuracy: 0.6279201224328593
Iteration:500  Loss:tensor(0.7888, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(70, device='cuda:0')
echo: 2
loss: 0.9037605492989599
accuracy: 0.6819905213270142
echo: 3
loss: 0.8128673688495328
accuracy: 0.7147709320695103
Iteration:1000  Loss:tensor(0.8192, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(76, device='cuda:0')
echo: 4
loss: 0.780035062706301
accuracy: 0.7302601698262242
echo: 5
loss: 0.7454142415128048
accuracy: 0.7375617101105845
echo: 6
loss: 0.7104008330553064
accuracy: 0.7530089849921011
Iteration:1500  Loss:tensor(0.7358, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(77, device='cuda:0')
echo: 7
loss: 0.6927582894173844
accuracy: 0.7587406200631911
echo: 8
loss: 0.6694729162900934
accuracy: 0.7661038704581359
Iteration:2000  Loss:tensor(0.7747, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(79, device='cuda:0')
echo: 9
loss: 0.6584453837001493
accuracy: 0.7710456161137441
echo: 10
loss: 0.6364815592483322
accuracy: 0.7793098341232227
Iteration:2500  Loss:tensor(0.5214, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(81, device='cuda:0')
echo: 11
loss: 0.6305720115442411
accuracy: 0.7849180489731438
echo: 12
loss: 0.6197367930581784
accuracy: 0.7878431082148499
echo: 13
loss: 0.6280289385556045
accuracy: 0.7885021721958925
Iteration:3000  Loss:tensor(0.6082, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(81, device='cuda:0')
echo: 14
loss: 0.5971633187402481
accuracy: 0.7964306872037915
echo: 15
loss: 0.6078298526917588
accuracy: 0.801024387835703
Iteration:3500  Loss:tensor(0.5317, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(82, device='cuda:0')
echo: 16
loss: 0.6422566942411576
accuracy: 0.7840837282780411
echo: 17
loss: 0.6388313801367701
accuracy: 0.7790531200631912
Iteration:4000  Loss:tensor(0.5793, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(82, device='cuda:0')
echo: 18
loss: 0.588689074273358
accuracy: 0.8000172788309636
echo: 19
loss: 0.5629046758486761
accuracy: 0.8058501184834124
echo: 20
loss: 0.5403035333936248
accuracy: 0.8145759281200632
Iteration:4500  Loss:tensor(0.4461, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(83, device='cuda:0')
echo: 21
loss: 0.5263787902079488
accuracy: 0.8209049170616114
echo: 22
loss: 0.5182436159436736
accuracy: 0.8224353278041073
Iteration:5000  Loss:tensor(0.6210, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(82, device='cuda:0')
echo: 23
loss: 0.5127828272315563
accuracy: 0.8264020537124803
echo: 24
loss: 0.49850694969367076
accuracy: 0.8319436216429701
echo: 25
loss: 0.48891443084766517
accuracy: 0.8355524289099525
Iteration:5500  Loss:tensor(0.4763, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(83, device='cuda:0')
echo: 26
loss: 0.4804712710504848
accuracy: 0.839879541864139
echo: 27
loss: 0.4774049168796901
accuracy: 0.8383046998420222
Iteration:6000  Loss:tensor(0.6206, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(83, device='cuda:0')
echo: 28
loss: 0.47583998464295085
accuracy: 0.8415210308056872
echo: 29
loss: 0.4658624090572104
accuracy: 0.8400646721958926
Iteration:6500  Loss:tensor(0.4345, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(83, device='cuda:0')
echo: 30
loss: 0.4609515264418453
accuracy: 0.8422294628751975
echo: 31
loss: 0.46587885400695256
accuracy: 0.843710505529226
echo: 32
loss: 0.44969048559383196
accuracy: 0.8474377962085308
Iteration:7000  Loss:tensor(0.3547, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(83, device='cuda:0')
echo: 33
loss: 0.4444709339695519
accuracy: 0.8512416074249605
echo: 34
loss: 0.4397483487829778
accuracy: 0.8520043443917852
Iteration:7500  Loss:tensor(0.4995, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 35
loss: 0.4293215764924813
accuracy: 0.8559488546603475
echo: 36
loss: 0.4253040437732263
accuracy: 0.85608214849921
Iteration:8000  Loss:tensor(0.4621, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 37
loss: 0.41726361737714557
accuracy: 0.8580395932069511
echo: 38
loss: 0.41774843244756005
accuracy: 0.8604783767772511
echo: 39
loss: 0.4139969300178555
accuracy: 0.8608930687203792
Iteration:8500  Loss:tensor(0.2662, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(84, device='cuda:0')
echo: 40
loss: 0.40948856809127954
accuracy: 0.8611176935229068
echo: 41
loss: 0.4047011120059479
accuracy: 0.8648449842022117
Iteration:9000  Loss:tensor(0.3045, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(84, device='cuda:0')
echo: 42
loss: 0.3920594899434049
accuracy: 0.8704531990521327
echo: 43
loss: 0.4121539771415611
accuracy: 0.8619939770932069
echo: 44
loss: 0.3924414797275552
accuracy: 0.8702631319115324
Iteration:9500  Loss:tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 45
loss: 0.3865356590793031
accuracy: 0.8729067930489731
echo: 46
loss: 0.3835393218632558
accuracy: 0.8716701224328594
Iteration:10000  Loss:tensor(0.3519, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 47
loss: 0.37445775204077714
accuracy: 0.8744051145339653
echo: 48
loss: 0.36916898205099513
accuracy: 0.875772610584518
Iteration:10500  Loss:tensor(0.5339, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(84, device='cuda:0')
echo: 49
loss: 0.4237100149359183
accuracy: 0.8574397709320695
echo: 50
loss: 0.3818124661230928
accuracy: 0.8729561611374407
echo: 51
loss: 0.35491499693190315
accuracy: 0.8796628159557662
Iteration:11000  Loss:tensor(0.2637, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(84, device='cuda:0')
echo: 52
loss: 0.35668780269781
accuracy: 0.8825088862559242
echo: 53
loss: 0.3422358072764501
accuracy: 0.8877394352290678
Iteration:11500  Loss:tensor(0.3382, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 54
loss: 0.3360349271111014
accuracy: 0.8867792259083729
echo: 55
loss: 0.33467272891535016
accuracy: 0.8877690560821484
Iteration:12000  Loss:tensor(0.3319, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 56
loss: 0.3312438693939227
accuracy: 0.8882972946287521
echo: 57
loss: 0.33070592900023077
accuracy: 0.8881121642969985
echo: 58
loss: 0.3221150813227016
accuracy: 0.8922738941548183
Iteration:12500  Loss:tensor(0.3755, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 59
loss: 0.3157157385236279
accuracy: 0.8957000394944707
echo: 60
loss: 0.31728882444978324
accuracy: 0.8956358609794628
Iteration:13000  Loss:tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 61
loss: 0.30977627175961625
accuracy: 0.8961887835703002
echo: 62
loss: 0.301057891116888
accuracy: 0.8997580963665087
Iteration:13500  Loss:tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 63
loss: 0.31001003383177717
accuracy: 0.8939869668246445
echo: 64
loss: 0.35418015859703317
accuracy: 0.8808501184834123
echo: 65
loss: 0.39488870138523136
accuracy: 0.868211887835703
Iteration:14000  Loss:tensor(0.3510, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 66
loss: 0.323624249812551
accuracy: 0.8917505924170617
echo: 67
loss: 0.30267913625421117
accuracy: 0.8995235979462874
Iteration:14500  Loss:tensor(0.2395, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 68
loss: 0.2870283438978602
accuracy: 0.9050799763033176
echo: 69
loss: 0.2802412183646342
accuracy: 0.9064375987361769
echo: 70
loss: 0.2765152212144074
accuracy: 0.9074743285939968
Iteration:15000  Loss:tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 71
loss: 0.26830242666023035
accuracy: 0.9101081161137441
echo: 72
loss: 0.2686573143042094
accuracy: 0.9092268957345973
Iteration:15500  Loss:tensor(0.2773, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 73
loss: 0.2613334676241988
accuracy: 0.9130257701421801
echo: 74
loss: 0.25330573772367143
accuracy: 0.9153608807266982
Iteration:16000  Loss:tensor(0.3153, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 75
loss: 0.2552506381301518
accuracy: 0.9142945300157977
echo: 76
loss: 0.2517301665168803
accuracy: 0.914516686413902
echo: 77
loss: 0.24620487124292773
accuracy: 0.9182958135860979
Iteration:16500  Loss:tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 78
loss: 0.23724029908813007
accuracy: 0.9192189968404423
echo: 79
loss: 0.2424367944493678
accuracy: 0.9197028041074249
Iteration:17000  Loss:tensor(0.2528, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 80
loss: 0.22632067205640377
accuracy: 0.9230598341232228
echo: 81
loss: 0.23119977893422566
accuracy: 0.9228500197472354
Iteration:17500  Loss:tensor(0.1811, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 82
loss: 0.22864949752651684
accuracy: 0.9230351500789888
echo: 83
loss: 0.22915098568980727
accuracy: 0.9232573064770931
echo: 84
loss: 0.22295498523101986
accuracy: 0.9232573064770931
Iteration:18000  Loss:tensor(0.2572, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 85
loss: 0.21821347970109414
accuracy: 0.925557859399684
echo: 86
loss: 0.21433642591345367
accuracy: 0.9271450434439178
Iteration:18500  Loss:tensor(0.2320, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 87
loss: 0.21485137084931558
accuracy: 0.9272166271721959
echo: 88
loss: 0.2083056040849731
accuracy: 0.9299614928909953
echo: 89
loss: 0.2036136859118656
accuracy: 0.9332271919431279
Iteration:19000  Loss:tensor(0.1573, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 90
loss: 0.1966895968851885
accuracy: 0.9357696484992101
echo: 91
loss: 0.34610275016718
accuracy: 0.8955297195892575
Iteration:19500  Loss:tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 92
loss: 0.23148001186655595
accuracy: 0.921596070300158
echo: 93
loss: 0.20312955897848753
accuracy: 0.9310648696682464
Iteration:20000  Loss:tensor(0.4599, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(80, device='cuda:0')
echo: 94
loss: 0.24167684257312974
accuracy: 0.9209987164296998
echo: 95
loss: 0.24210964178587024
accuracy: 0.9204112361769352
echo: 96
loss: 0.20097244078937865
accuracy: 0.9313265205371248
Iteration:20500  Loss:tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 97
loss: 0.18699194822831178
accuracy: 0.93611275671406
echo: 98
loss: 0.18233963594688057
accuracy: 0.9390723736176936
Iteration:21000  Loss:tensor(0.2748, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 99
loss: 0.17857001824260324
accuracy: 0.9393759873617694
echo: 100
loss: 0.16540658345084056
accuracy: 0.945351994470774
Iteration:21500  Loss:tensor(0.2235, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 101
loss: 0.16064481790314353
accuracy: 0.9465467022116903
echo: 102
loss: 0.16717221985142944
accuracy: 0.944742298578199
echo: 103
loss: 0.15838586830344245
accuracy: 0.9472230450236966
Iteration:22000  Loss:tensor(0.2063, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 104
loss: 0.15597709220661937
accuracy: 0.9470749407582938
echo: 105
loss: 0.16037632076519925
accuracy: 0.9465096761453397
Iteration:22500  Loss:tensor(0.2086, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 106
loss: 0.1583010141706862
accuracy: 0.94791913507109
echo: 107
loss: 0.1538045992677528
accuracy: 0.9496667654028436
echo: 108
loss: 0.1504751456221698
accuracy: 0.9488546603475514
Iteration:23000  Loss:tensor(0.1676, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 109
loss: 0.14750307771902513
accuracy: 0.9503751974723539
echo: 110
loss: 0.14546342252343186
accuracy: 0.9511107819905212
Iteration:23500  Loss:tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 111
loss: 0.15220880202984358
accuracy: 0.9491385268562401
echo: 112
loss: 0.14386107880286697
accuracy: 0.9530756319115324
Iteration:24000  Loss:tensor(0.2464, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 113
loss: 0.13861575754474126
accuracy: 0.9541814770932069
echo: 114
loss: 0.15002339718183635
accuracy: 0.9514094589257505
echo: 115
loss: 0.13924255594611168
accuracy: 0.9536236176935229
Iteration:24500  Loss:tensor(0.0798, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 116
loss: 0.13524889064979215
accuracy: 0.9547368680884676
echo: 117
loss: 0.13448280758131737
accuracy: 0.9556872037914692
Iteration:25000  Loss:tensor(0.0713, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 118
loss: 0.13755522656885652
accuracy: 0.9544505331753554
echo: 119
loss: 0.129332656950041
accuracy: 0.956891785150079
Iteration:25500  Loss:tensor(0.1094, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 120
loss: 0.1251116245631923
accuracy: 0.9601772314375987
echo: 121
loss: 0.12582181676586657
accuracy: 0.9585308056872038
echo: 122
loss: 0.18654128570127262
accuracy: 0.9386626184834124
Iteration:26000  Loss:tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 123
loss: 0.13587903180181699
accuracy: 0.9538136848341232
echo: 124
loss: 0.12425688625935695
accuracy: 0.9599279225908373
Iteration:26500  Loss:tensor(0.1226, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 125
loss: 0.12416339647995916
accuracy: 0.960658570300158
echo: 126
loss: 0.11598813724461325
accuracy: 0.9614830173775671
Iteration:27000  Loss:tensor(0.1570, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 127
loss: 0.11004591318315239
accuracy: 0.9627024091627172
echo: 128
loss: 0.10925214504602396
accuracy: 0.9642969984202212
echo: 129
loss: 0.1081996059036368
accuracy: 0.9644475710900474
Iteration:27500  Loss:tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 130
loss: 0.1091206275385703
accuracy: 0.9642550355450237
echo: 131
loss: 0.11273835015028574
accuracy: 0.9627715244865719
Iteration:28000  Loss:tensor(0.1067, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 132
loss: 0.10839110690553042
accuracy: 0.9634725513428121
echo: 133
loss: 0.10352938017538656
accuracy: 0.9658570300157977
echo: 134
loss: 0.10506100016888849
accuracy: 0.9656225315955766
Iteration:28500  Loss:tensor(0.1391, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 135
loss: 0.1042563759355466
accuracy: 0.965521327014218
echo: 136
loss: 0.10267788291824938
accuracy: 0.9661754541864139
Iteration:29000  Loss:tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 137
loss: 0.10442220855733794
accuracy: 0.9669999012638231
echo: 138
loss: 0.10038882367295253
accuracy: 0.9675626974723539
Iteration:29500  Loss:tensor(0.1156, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 139
loss: 0.09535372179548887
accuracy: 0.9686389218009479
echo: 140
loss: 0.09606714205048378
accuracy: 0.9685278436018957
echo: 141
loss: 0.09854385060792285
accuracy: 0.9673331358609795
Iteration:30000  Loss:tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
echo: 142
loss: 0.10648829959138734
accuracy: 0.9662964060031596
echo: 143
loss: 0.09276409790590759
accuracy: 0.9693325434439178
Iteration:30500  Loss:tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 144
loss: 0.08976491673968696
accuracy: 0.9704038309636651
echo: 145
loss: 0.08937182145908264
accuracy: 0.9717046800947867
Iteration:31000  Loss:tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 146
loss: 0.08724683434018309
accuracy: 0.9722625394944707
echo: 147
loss: 0.08968947299919422
accuracy: 0.9701446484992101
echo: 148
loss: 0.08057398008297405
accuracy: 0.9738497235387046
Iteration:31500  Loss:tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 149
loss: 0.08783868490166574
accuracy: 0.9713739139020536
echo: 150
loss: 0.09086623208341299
accuracy: 0.9702236374407582
Iteration:32000  Loss:tensor(0.1566, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 151
loss: 0.08428804642604708
accuracy: 0.9719638625592417
echo: 152
loss: 0.08564220861447931
accuracy: 0.9728919826224328
echo: 153
loss: 0.1441985863256511
accuracy: 0.9536334913112164
Iteration:32500  Loss:tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 154
loss: 0.09846863148831078
accuracy: 0.968367397314376
echo: 155
loss: 0.08335714890528911
accuracy: 0.9731832543443918
Iteration:33000  Loss:tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 156
loss: 0.07160086471199001
accuracy: 0.975817041864139
echo: 157
loss: 0.07384500309154038
accuracy: 0.975733116113744
Iteration:33500  Loss:tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 158
loss: 0.07145754555549243
accuracy: 0.9764464849921011
echo: 159
loss: 0.06940974502590312
accuracy: 0.9776979660347552
echo: 160
loss: 0.06903001067550826
accuracy: 0.9773326421800947
Iteration:34000  Loss:tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 161
loss: 0.1061708740536918
accuracy: 0.965780509478673
echo: 162
loss: 0.08639222059522478
accuracy: 0.9715146129541865
Iteration:34500  Loss:tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 163
loss: 0.0744358895178796
accuracy: 0.9764464849921011
echo: 164
loss: 0.06817458455243382
accuracy: 0.9777325236966824
Iteration:35000  Loss:tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 165
loss: 0.07197831163703688
accuracy: 0.9760786927330174
echo: 166
loss: 0.06697048036981885
accuracy: 0.9784483609794629
echo: 167
loss: 0.06844119135272729
accuracy: 0.9775572669826224
Iteration:35500  Loss:tensor(0.0765, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 168
loss: 0.0665103228612675
accuracy: 0.9781101895734597
echo: 169
loss: 0.06432425989041114
accuracy: 0.9788482424960505
Iteration:36000  Loss:tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 170
loss: 0.06644735900217323
accuracy: 0.9796998420221169
echo: 171
loss: 0.0627804798475727
accuracy: 0.9801885860979463
Iteration:36500  Loss:tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 172
loss: 0.07201225458428052
accuracy: 0.9773030213270142
echo: 173
loss: 0.0648284416416245
accuracy: 0.9804477685624013
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
echo: 0
loss: 0.059336188988610046
accuracy: 0.9808416553825321
Iteration:500  Loss:tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 1
loss: 0.1022642787857096
accuracy: 0.9678243483412322
Iteration:1000  Loss:tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 2
loss: 0.05359939828248015
accuracy: 0.9829627200406228
Iteration:1500  Loss:tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 3
loss: 0.04501885009082078
accuracy: 0.9854064404197698
Iteration:2000  Loss:tensor(0.1192, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 4
loss: 0.044580591267628054
accuracy: 0.9874058480027081
Iteration:2500  Loss:tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 5
loss: 0.037499788810357766
accuracy: 0.9868927725118484
echo: 6
loss: 0.03436827177504051
accuracy: 0.9882574475287745
Iteration:3000  Loss:tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 7
loss: 0.04321070329889752
accuracy: 0.9888181279620853
Iteration:3500  Loss:tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 8
loss: 0.045367361649692114
accuracy: 0.9884108412322274
Iteration:4000  Loss:tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 9
loss: 0.05019842914991981
accuracy: 0.985781990521327
Iteration:4500  Loss:tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 10
loss: 0.03645644758571981
accuracy: 0.988077606635071
Iteration:5000  Loss:tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 11
loss: 0.03548919951230932
accuracy: 0.9898019634394042
echo: 12
loss: 0.028094021337530552
accuracy: 0.9915580568720379
Iteration:5500  Loss:tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 13
loss: 0.033105915479066286
accuracy: 0.9886277081922816
Iteration:6000  Loss:tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 14
loss: 0.02485057231401848
accuracy: 0.9922139471902506
Iteration:6500  Loss:tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 15
loss: 0.02838480336397392
accuracy: 0.9923356042654028
Iteration:7000  Loss:tensor(0.5315, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 16
loss: 0.02683139245176988
accuracy: 0.9914840047393365
Iteration:7500  Loss:tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 17
loss: 0.026950187654503716
accuracy: 0.9917061611374408
Iteration:8000  Loss:tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 18
loss: 0.09836956780289093
accuracy: 0.9709186696005416
echo: 19
loss: 0.03940893113982789
accuracy: 0.986252750507786
Iteration:8500  Loss:tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 20
loss: 0.03322988432711785
accuracy: 0.988225710900474
Iteration:9000  Loss:tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 21
loss: 0.03242829916292528
accuracy: 0.9890667315504401
Iteration:9500  Loss:tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 22
loss: 0.033479660496466584
accuracy: 0.989114336492891
Iteration:10000  Loss:tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 23
loss: 0.028893395369514928
accuracy: 0.9915950829383886
Iteration:10500  Loss:tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 24
loss: 0.0365283253548338
accuracy: 0.99062711577522
echo: 25
loss: 0.05060659018698285
accuracy: 0.9842639218009479
Iteration:11000  Loss:tensor(1.6980, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 26
loss: 0.07825759970207845
accuracy: 0.9794082176709545
Iteration:11500  Loss:tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 27
loss: 0.033828472568525524
accuracy: 0.988437288422478
Iteration:12000  Loss:tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 28
loss: 0.02864016381851552
accuracy: 0.9897755162491536
Iteration:12500  Loss:tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 29
loss: 0.03122996652203113
accuracy: 0.9912618483412322
Iteration:13000  Loss:tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 30
loss: 0.025920033888004155
accuracy: 0.9914840047393365
Iteration:13500  Loss:tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 31
loss: 0.029050175340430175
accuracy: 0.9913676371022342
echo: 32
loss: 0.022610766719916384
accuracy: 0.9922985781990521
Iteration:14000  Loss:tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 33
loss: 0.024739380738443045
accuracy: 0.9925207345971564
Iteration:14500  Loss:tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 34
loss: 0.021644297330110595
accuracy: 0.9925947867298578
Iteration:15000  Loss:tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 35
loss: 0.025412093865921307
accuracy: 0.9925154451591063
Iteration:15500  Loss:tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 36
loss: 0.022157651426047704
accuracy: 0.9923303148273527
Iteration:16000  Loss:tensor(0.0327, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 37
loss: 0.025859926706836536
accuracy: 0.9930708361543669
echo: 38
loss: 0.022721180605417408
accuracy: 0.9929650473933649
Iteration:16500  Loss:tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 39
loss: 0.025065736591890982
accuracy: 0.9925577606635071
Iteration:17000  Loss:tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 40
loss: 0.021093537405042762
accuracy: 0.9923726303317536
Iteration:17500  Loss:tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 41
loss: 0.023536613390210494
accuracy: 0.9923673408937034
Iteration:18000  Loss:tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 42
loss: 0.021613969403027747
accuracy: 0.9922615521327014
Iteration:18500  Loss:tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 43
loss: 0.020558852124647503
accuracy: 0.9925154451591063
echo: 44
loss: 0.021385237085605392
accuracy: 0.9925947867298578
Iteration:19000  Loss:tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 45
loss: 0.02079908796740581
accuracy: 0.9929650473933649
Iteration:19500  Loss:tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 46
loss: 0.024238952095824474
accuracy: 0.9922245260663507
Iteration:20000  Loss:tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 47
loss: 0.01959189851862109
accuracy: 0.9931078622207176
Iteration:20500  Loss:tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 48
loss: 0.018785182532155886
accuracy: 0.9938166469194313
Iteration:21000  Loss:tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 49
loss: 0.02036334705341528
accuracy: 0.9937743314150304
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 3, 32, 32]               6
            Conv2d-2           [-1, 64, 16, 16]           9,408
       BatchNorm2d-3           [-1, 64, 16, 16]             128
              ReLU-4           [-1, 64, 16, 16]               0
         MaxPool2d-5             [-1, 64, 8, 8]               0
            Conv2d-6             [-1, 64, 8, 8]           4,096
       BatchNorm2d-7             [-1, 64, 8, 8]             128
              ReLU-8             [-1, 64, 8, 8]               0
            Conv2d-9             [-1, 64, 8, 8]          36,864
      BatchNorm2d-10             [-1, 64, 8, 8]             128
             ReLU-11             [-1, 64, 8, 8]               0
           Conv2d-12            [-1, 256, 8, 8]          16,384
      BatchNorm2d-13            [-1, 256, 8, 8]             512
           Conv2d-14            [-1, 256, 8, 8]          16,384
      BatchNorm2d-15            [-1, 256, 8, 8]             512
             ReLU-16            [-1, 256, 8, 8]               0
       Bottleneck-17            [-1, 256, 8, 8]               0
           Conv2d-18             [-1, 64, 8, 8]          16,384
      BatchNorm2d-19             [-1, 64, 8, 8]             128
             ReLU-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,864
      BatchNorm2d-22             [-1, 64, 8, 8]             128
             ReLU-23             [-1, 64, 8, 8]               0
           Conv2d-24            [-1, 256, 8, 8]          16,384
      BatchNorm2d-25            [-1, 256, 8, 8]             512
             ReLU-26            [-1, 256, 8, 8]               0
       Bottleneck-27            [-1, 256, 8, 8]               0
           Conv2d-28             [-1, 64, 8, 8]          16,384
      BatchNorm2d-29             [-1, 64, 8, 8]             128
             ReLU-30             [-1, 64, 8, 8]               0
           Conv2d-31             [-1, 64, 8, 8]          36,864
      BatchNorm2d-32             [-1, 64, 8, 8]             128
             ReLU-33             [-1, 64, 8, 8]               0
           Conv2d-34            [-1, 256, 8, 8]          16,384
      BatchNorm2d-35            [-1, 256, 8, 8]             512
             ReLU-36            [-1, 256, 8, 8]               0
       Bottleneck-37            [-1, 256, 8, 8]               0
           Conv2d-38            [-1, 128, 8, 8]          32,768
      BatchNorm2d-39            [-1, 128, 8, 8]             256
             ReLU-40            [-1, 128, 8, 8]               0
           Conv2d-41            [-1, 128, 4, 4]         147,456
      BatchNorm2d-42            [-1, 128, 4, 4]             256
             ReLU-43            [-1, 128, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]          65,536
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
           Conv2d-46            [-1, 512, 4, 4]         131,072
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024
             ReLU-48            [-1, 512, 4, 4]               0
       Bottleneck-49            [-1, 512, 4, 4]               0
           Conv2d-50            [-1, 128, 4, 4]          65,536
      BatchNorm2d-51            [-1, 128, 4, 4]             256
             ReLU-52            [-1, 128, 4, 4]               0
           Conv2d-53            [-1, 128, 4, 4]         147,456
      BatchNorm2d-54            [-1, 128, 4, 4]             256
             ReLU-55            [-1, 128, 4, 4]               0
           Conv2d-56            [-1, 512, 4, 4]          65,536
      BatchNorm2d-57            [-1, 512, 4, 4]           1,024
             ReLU-58            [-1, 512, 4, 4]               0
       Bottleneck-59            [-1, 512, 4, 4]               0
           Conv2d-60            [-1, 128, 4, 4]          65,536
      BatchNorm2d-61            [-1, 128, 4, 4]             256
             ReLU-62            [-1, 128, 4, 4]               0
           Conv2d-63            [-1, 128, 4, 4]         147,456
      BatchNorm2d-64            [-1, 128, 4, 4]             256
             ReLU-65            [-1, 128, 4, 4]               0
           Conv2d-66            [-1, 512, 4, 4]          65,536
      BatchNorm2d-67            [-1, 512, 4, 4]           1,024
             ReLU-68            [-1, 512, 4, 4]               0
       Bottleneck-69            [-1, 512, 4, 4]               0
           Conv2d-70            [-1, 128, 4, 4]          65,536
      BatchNorm2d-71            [-1, 128, 4, 4]             256
             ReLU-72            [-1, 128, 4, 4]               0
           Conv2d-73            [-1, 128, 4, 4]         147,456
      BatchNorm2d-74            [-1, 128, 4, 4]             256
             ReLU-75            [-1, 128, 4, 4]               0
           Conv2d-76            [-1, 512, 4, 4]          65,536
      BatchNorm2d-77            [-1, 512, 4, 4]           1,024
             ReLU-78            [-1, 512, 4, 4]               0
       Bottleneck-79            [-1, 512, 4, 4]               0
           Conv2d-80            [-1, 256, 4, 4]         131,072
      BatchNorm2d-81            [-1, 256, 4, 4]             512
             ReLU-82            [-1, 256, 4, 4]               0
           Conv2d-83            [-1, 256, 2, 2]         589,824
      BatchNorm2d-84            [-1, 256, 2, 2]             512
             ReLU-85            [-1, 256, 2, 2]               0
           Conv2d-86           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-87           [-1, 1024, 2, 2]           2,048
           Conv2d-88           [-1, 1024, 2, 2]         524,288
      BatchNorm2d-89           [-1, 1024, 2, 2]           2,048
             ReLU-90           [-1, 1024, 2, 2]               0
       Bottleneck-91           [-1, 1024, 2, 2]               0
           Conv2d-92            [-1, 256, 2, 2]         262,144
      BatchNorm2d-93            [-1, 256, 2, 2]             512
             ReLU-94            [-1, 256, 2, 2]               0
           Conv2d-95            [-1, 256, 2, 2]         589,824
      BatchNorm2d-96            [-1, 256, 2, 2]             512
             ReLU-97            [-1, 256, 2, 2]               0
           Conv2d-98           [-1, 1024, 2, 2]         262,144
      BatchNorm2d-99           [-1, 1024, 2, 2]           2,048
            ReLU-100           [-1, 1024, 2, 2]               0
      Bottleneck-101           [-1, 1024, 2, 2]               0
          Conv2d-102            [-1, 256, 2, 2]         262,144
     BatchNorm2d-103            [-1, 256, 2, 2]             512
            ReLU-104            [-1, 256, 2, 2]               0
          Conv2d-105            [-1, 256, 2, 2]         589,824
     BatchNorm2d-106            [-1, 256, 2, 2]             512
            ReLU-107            [-1, 256, 2, 2]               0
          Conv2d-108           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048
            ReLU-110           [-1, 1024, 2, 2]               0
      Bottleneck-111           [-1, 1024, 2, 2]               0
          Conv2d-112            [-1, 256, 2, 2]         262,144
     BatchNorm2d-113            [-1, 256, 2, 2]             512
            ReLU-114            [-1, 256, 2, 2]               0
          Conv2d-115            [-1, 256, 2, 2]         589,824
     BatchNorm2d-116            [-1, 256, 2, 2]             512
            ReLU-117            [-1, 256, 2, 2]               0
          Conv2d-118           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048
            ReLU-120           [-1, 1024, 2, 2]               0
      Bottleneck-121           [-1, 1024, 2, 2]               0
          Conv2d-122            [-1, 256, 2, 2]         262,144
     BatchNorm2d-123            [-1, 256, 2, 2]             512
            ReLU-124            [-1, 256, 2, 2]               0
          Conv2d-125            [-1, 256, 2, 2]         589,824
     BatchNorm2d-126            [-1, 256, 2, 2]             512
            ReLU-127            [-1, 256, 2, 2]               0
          Conv2d-128           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-129           [-1, 1024, 2, 2]           2,048
            ReLU-130           [-1, 1024, 2, 2]               0
      Bottleneck-131           [-1, 1024, 2, 2]               0
          Conv2d-132            [-1, 256, 2, 2]         262,144
     BatchNorm2d-133            [-1, 256, 2, 2]             512
            ReLU-134            [-1, 256, 2, 2]               0
          Conv2d-135            [-1, 256, 2, 2]         589,824
     BatchNorm2d-136            [-1, 256, 2, 2]             512
            ReLU-137            [-1, 256, 2, 2]               0
          Conv2d-138           [-1, 1024, 2, 2]         262,144
     BatchNorm2d-139           [-1, 1024, 2, 2]           2,048
            ReLU-140           [-1, 1024, 2, 2]               0
      Bottleneck-141           [-1, 1024, 2, 2]               0
          Conv2d-142            [-1, 512, 2, 2]         524,288
     BatchNorm2d-143            [-1, 512, 2, 2]           1,024
            ReLU-144            [-1, 512, 2, 2]               0
          Conv2d-145            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-146            [-1, 512, 1, 1]           1,024
            ReLU-147            [-1, 512, 1, 1]               0
          Conv2d-148           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-149           [-1, 2048, 1, 1]           4,096
          Conv2d-150           [-1, 2048, 1, 1]       2,097,152
     BatchNorm2d-151           [-1, 2048, 1, 1]           4,096
            ReLU-152           [-1, 2048, 1, 1]               0
      Bottleneck-153           [-1, 2048, 1, 1]               0
          Conv2d-154            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-155            [-1, 512, 1, 1]           1,024
            ReLU-156            [-1, 512, 1, 1]               0
          Conv2d-157            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-158            [-1, 512, 1, 1]           1,024
            ReLU-159            [-1, 512, 1, 1]               0
          Conv2d-160           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-161           [-1, 2048, 1, 1]           4,096
            ReLU-162           [-1, 2048, 1, 1]               0
      Bottleneck-163           [-1, 2048, 1, 1]               0
          Conv2d-164            [-1, 512, 1, 1]       1,048,576
     BatchNorm2d-165            [-1, 512, 1, 1]           1,024
            ReLU-166            [-1, 512, 1, 1]               0
          Conv2d-167            [-1, 512, 1, 1]       2,359,296
     BatchNorm2d-168            [-1, 512, 1, 1]           1,024
            ReLU-169            [-1, 512, 1, 1]               0
          Conv2d-170           [-1, 2048, 1, 1]       1,048,576
     BatchNorm2d-171           [-1, 2048, 1, 1]           4,096
            ReLU-172           [-1, 2048, 1, 1]               0
      Bottleneck-173           [-1, 2048, 1, 1]               0
AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0
          Linear-175                 [-1, 1000]       2,049,000
          ResNet-176                 [-1, 1000]               0
     BatchNorm1d-177                 [-1, 1000]           2,000
         Dropout-178                 [-1, 1000]               0
          Linear-179                 [-1, 4096]       4,100,096
     BatchNorm1d-180                 [-1, 4096]           8,192
         Dropout-181                 [-1, 4096]               0
          Linear-182                   [-1, 10]          40,970
================================================================
Total params: 29,708,296
Trainable params: 29,708,296
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.01
Params size (MB): 113.33
Estimated Total Size (MB): 119.34
----------------------------------------------------------------
Iteration:500  Loss:tensor(0.3833, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:1000  Loss:tensor(0.5677, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:1500  Loss:tensor(0.4607, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:2000  Loss:tensor(0.5447, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:2500  Loss:tensor(0.3844, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 0
loss: 0.48390053657558857
accuracy: 0.8299331062401264
Iteration:3000  Loss:tensor(0.3331, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:3500  Loss:tensor(0.2494, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:4000  Loss:tensor(0.4101, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:4500  Loss:tensor(0.3466, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:5000  Loss:tensor(0.3805, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 1
loss: 0.43283202287286376
accuracy: 0.8406027843601895
Iteration:5500  Loss:tensor(0.3835, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:6000  Loss:tensor(0.2054, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:6500  Loss:tensor(0.3752, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:7000  Loss:tensor(0.4274, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:7500  Loss:tensor(0.4195, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 2
loss: 0.3873858434952925
accuracy: 0.8536544727488151
Iteration:8000  Loss:tensor(0.3520, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:8500  Loss:tensor(0.4700, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:9000  Loss:tensor(0.3680, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:9500  Loss:tensor(0.4101, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:10000  Loss:tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 3
loss: 0.3944973392974097
accuracy: 0.8534138033175356
Iteration:10500  Loss:tensor(0.4196, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:11000  Loss:tensor(0.3120, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:11500  Loss:tensor(0.3888, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:12000  Loss:tensor(0.3386, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:12500  Loss:tensor(0.4415, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 4
loss: 0.3595927439506444
accuracy: 0.8658237065560821
Iteration:13000  Loss:tensor(0.4813, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:13500  Loss:tensor(0.3938, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:14000  Loss:tensor(0.3249, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:14500  Loss:tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:15000  Loss:tensor(0.2678, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 5
loss: 0.3454085281883818
accuracy: 0.8725439375987362
Iteration:15500  Loss:tensor(0.2750, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:16000  Loss:tensor(0.2392, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:16500  Loss:tensor(0.2547, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:17000  Loss:tensor(0.2703, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:17500  Loss:tensor(0.4533, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 6
loss: 0.31699112654438516
accuracy: 0.8848365916271722
Iteration:18000  Loss:tensor(0.1917, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:18500  Loss:tensor(0.3000, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:19000  Loss:tensor(0.3207, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:19500  Loss:tensor(0.1888, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:20000  Loss:tensor(0.3655, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 7
loss: 0.3190535642809895
accuracy: 0.8854968898104265
Iteration:20500  Loss:tensor(0.4066, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:21000  Loss:tensor(0.3217, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:21500  Loss:tensor(0.3966, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:22000  Loss:tensor(0.2038, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:22500  Loss:tensor(0.1858, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 8
loss: 0.33449003529274396
accuracy: 0.8818189672195893
Iteration:23000  Loss:tensor(0.1881, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:23500  Loss:tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:24000  Loss:tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:24500  Loss:tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:25000  Loss:tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 9
loss: 0.29377798671358946
accuracy: 0.8948583135860979
Iteration:25500  Loss:tensor(0.3048, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:26000  Loss:tensor(0.3929, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:26500  Loss:tensor(0.4160, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:27000  Loss:tensor(0.2295, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:27500  Loss:tensor(0.2250, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 10
loss: 0.30509470923734594
accuracy: 0.8891377863349131
Iteration:28000  Loss:tensor(0.3169, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:28500  Loss:tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:29000  Loss:tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:29500  Loss:tensor(0.2219, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:30000  Loss:tensor(0.4990, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 11
loss: 0.32531072658090887
accuracy: 0.8808748025276462
Iteration:30500  Loss:tensor(0.3858, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:31000  Loss:tensor(0.2492, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:31500  Loss:tensor(0.3555, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:32000  Loss:tensor(0.9748, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:32500  Loss:tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 12
loss: 0.3076444516079074
accuracy: 0.8891377863349131
Iteration:33000  Loss:tensor(0.2438, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:33500  Loss:tensor(0.3299, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:34000  Loss:tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:34500  Loss:tensor(0.2931, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:35000  Loss:tensor(0.1431, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 13
loss: 0.2782627644449896
accuracy: 0.8998876875987362
Iteration:35500  Loss:tensor(0.2417, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:36000  Loss:tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:36500  Loss:tensor(0.1553, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:37000  Loss:tensor(0.3102, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:37500  Loss:tensor(0.1937, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 14
loss: 0.26890946982213626
accuracy: 0.9037322274881516
Iteration:38000  Loss:tensor(0.3277, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:38500  Loss:tensor(0.3070, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:39000  Loss:tensor(0.1846, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:39500  Loss:tensor(0.1643, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:40000  Loss:tensor(0.1396, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:40500  Loss:tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 15
loss: 0.252572491426627
accuracy: 0.9090639810426541
Iteration:41000  Loss:tensor(0.3864, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:41500  Loss:tensor(0.2182, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:42000  Loss:tensor(0.3395, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:42500  Loss:tensor(0.1941, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:43000  Loss:tensor(0.2447, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 16
loss: 0.28067160978042305
accuracy: 0.8988509577409163
Iteration:43500  Loss:tensor(0.1367, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:44000  Loss:tensor(0.1797, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:44500  Loss:tensor(0.2373, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:45000  Loss:tensor(0.2041, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:45500  Loss:tensor(0.2610, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 17
loss: 0.2551025910609024
accuracy: 0.9080334221958926
Iteration:46000  Loss:tensor(0.1338, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:46500  Loss:tensor(0.3219, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:47000  Loss:tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:47500  Loss:tensor(0.1808, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:48000  Loss:tensor(0.2005, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 18
loss: 0.2508769160854567
accuracy: 0.909458925750395
Iteration:48500  Loss:tensor(0.2642, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:49000  Loss:tensor(0.3028, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:49500  Loss:tensor(0.2654, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:50000  Loss:tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:50500  Loss:tensor(0.1615, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 19
loss: 0.23815592109427255
accuracy: 0.9154756615323855
Iteration:51000  Loss:tensor(0.2088, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:51500  Loss:tensor(0.4407, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:52000  Loss:tensor(0.2701, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:52500  Loss:tensor(0.4556, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:53000  Loss:tensor(0.2370, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 20
loss: 0.26631224235758116
accuracy: 0.9047381022906793
Iteration:53500  Loss:tensor(0.2260, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:54000  Loss:tensor(0.3174, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:54500  Loss:tensor(0.3238, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:55000  Loss:tensor(0.2697, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:55500  Loss:tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 21
loss: 0.24918237690170889
accuracy: 0.9117175157977883
Iteration:56000  Loss:tensor(0.1578, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:56500  Loss:tensor(0.1750, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:57000  Loss:tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:57500  Loss:tensor(0.4209, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:58000  Loss:tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 22
loss: 0.24469190852578265
accuracy: 0.9119828692733017
Iteration:58500  Loss:tensor(0.2246, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:59000  Loss:tensor(0.2308, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:59500  Loss:tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:60000  Loss:tensor(0.2272, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:60500  Loss:tensor(0.4139, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 23
loss: 0.23279086709475677
accuracy: 0.9169073360979463
Iteration:61000  Loss:tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:61500  Loss:tensor(0.3815, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:62000  Loss:tensor(0.1878, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:62500  Loss:tensor(0.2777, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:63000  Loss:tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 24
loss: 0.2602276147959686
accuracy: 0.9070398894154819
Iteration:63500  Loss:tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:64000  Loss:tensor(0.2542, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:64500  Loss:tensor(0.1876, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:65000  Loss:tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:65500  Loss:tensor(0.3304, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 25
loss: 0.23391049232857675
accuracy: 0.9166172985781991
Iteration:66000  Loss:tensor(0.2730, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:66500  Loss:tensor(0.1555, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:67000  Loss:tensor(0.1704, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:67500  Loss:tensor(0.3318, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:68000  Loss:tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 26
loss: 0.25754359087172607
accuracy: 0.9062931970774092
Iteration:68500  Loss:tensor(0.3151, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(85, device='cuda:0')
Iteration:69000  Loss:tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:69500  Loss:tensor(0.1935, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:70000  Loss:tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:70500  Loss:tensor(0.2003, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 27
loss: 0.2412997128391906
accuracy: 0.9130010860979463
Iteration:71000  Loss:tensor(0.0997, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:71500  Loss:tensor(0.1959, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:72000  Loss:tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:72500  Loss:tensor(0.1443, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:73000  Loss:tensor(0.3330, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 28
loss: 0.23267614120385047
accuracy: 0.916685179699842
Iteration:73500  Loss:tensor(0.2307, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:74000  Loss:tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:74500  Loss:tensor(0.2229, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:75000  Loss:tensor(0.2522, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:75500  Loss:tensor(0.1618, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 29
loss: 0.2175848664911567
accuracy: 0.9217700928120063
Iteration:76000  Loss:tensor(0.1237, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:76500  Loss:tensor(0.1702, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:77000  Loss:tensor(0.2075, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:77500  Loss:tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:78000  Loss:tensor(0.2609, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 30
loss: 0.19825616613983826
accuracy: 0.9288297294628752
Iteration:78500  Loss:tensor(0.1769, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:79000  Loss:tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:79500  Loss:tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:80000  Loss:tensor(0.1870, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:80500  Loss:tensor(0.2519, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:81000  Loss:tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 31
loss: 0.1930365080748042
accuracy: 0.9311932266982622
Iteration:81500  Loss:tensor(0.1566, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:82000  Loss:tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:82500  Loss:tensor(0.2866, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:83000  Loss:tensor(0.1466, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:83500  Loss:tensor(0.1239, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 32
loss: 0.19002090915919856
accuracy: 0.9319584320695102
Iteration:84000  Loss:tensor(0.1047, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:84500  Loss:tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:85000  Loss:tensor(0.1885, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:85500  Loss:tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:86000  Loss:tensor(0.1025, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 33
loss: 0.18901752261444926
accuracy: 0.9322978376777251
Iteration:86500  Loss:tensor(0.2577, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:87000  Loss:tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:87500  Loss:tensor(0.1546, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:88000  Loss:tensor(0.1343, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:88500  Loss:tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 34
loss: 0.18732394161523802
accuracy: 0.9330260169826224
Iteration:89000  Loss:tensor(0.1867, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:89500  Loss:tensor(0.1658, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:90000  Loss:tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:90500  Loss:tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:91000  Loss:tensor(0.2265, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 35
loss: 0.18558344841930327
accuracy: 0.9335073558451816
Iteration:91500  Loss:tensor(0.1124, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:92000  Loss:tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:92500  Loss:tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:93000  Loss:tensor(0.2996, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:93500  Loss:tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 36
loss: 0.18425445702282997
accuracy: 0.9336369470774092
Iteration:94000  Loss:tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:94500  Loss:tensor(0.2172, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:95000  Loss:tensor(0.1890, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:95500  Loss:tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:96000  Loss:tensor(0.2193, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 37
loss: 0.18367152323499086
accuracy: 0.9341923380726699
Iteration:96500  Loss:tensor(0.1564, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:97000  Loss:tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:97500  Loss:tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:98000  Loss:tensor(0.1173, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:98500  Loss:tensor(0.2224, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 38
loss: 0.18349707556820782
accuracy: 0.9340072077409163
Iteration:99000  Loss:tensor(0.2600, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:99500  Loss:tensor(0.2332, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:100000  Loss:tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:100500  Loss:tensor(0.1736, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:101000  Loss:tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 39
loss: 0.18452997368909008
accuracy: 0.9342417061611374
Iteration:101500  Loss:tensor(0.2160, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:102000  Loss:tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:102500  Loss:tensor(0.2645, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:103000  Loss:tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:103500  Loss:tensor(0.1603, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 40
loss: 0.18115566575923261
accuracy: 0.9350994766982622
Iteration:104000  Loss:tensor(0.1674, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:104500  Loss:tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:105000  Loss:tensor(0.1464, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:105500  Loss:tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:106000  Loss:tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 41
loss: 0.18028025834204697
accuracy: 0.9355623025276462
Iteration:106500  Loss:tensor(0.1751, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:107000  Loss:tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:107500  Loss:tensor(0.1212, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:108000  Loss:tensor(0.1231, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:108500  Loss:tensor(0.1103, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 42
loss: 0.1793769824636385
accuracy: 0.935778287914692
Iteration:109000  Loss:tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:109500  Loss:tensor(0.1713, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:110000  Loss:tensor(0.3927, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:110500  Loss:tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:111000  Loss:tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 43
loss: 0.17961959317503098
accuracy: 0.9353895142180095
Iteration:111500  Loss:tensor(0.2865, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:112000  Loss:tensor(0.1613, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:112500  Loss:tensor(0.1835, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:113000  Loss:tensor(0.1266, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:113500  Loss:tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 44
loss: 0.17974755068355214
accuracy: 0.934864978278041
Iteration:114000  Loss:tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:114500  Loss:tensor(0.1165, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:115000  Loss:tensor(0.1797, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:115500  Loss:tensor(0.1713, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:116000  Loss:tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 45
loss: 0.17815801865049
accuracy: 0.9366237164296999
Iteration:116500  Loss:tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:117000  Loss:tensor(0.2615, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:117500  Loss:tensor(0.2649, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:118000  Loss:tensor(0.1844, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:118500  Loss:tensor(0.2759, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:119000  Loss:tensor(0.1359, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 46
loss: 0.17915054237746633
accuracy: 0.9363151658767772
Iteration:119500  Loss:tensor(0.1816, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:120000  Loss:tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:120500  Loss:tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:121000  Loss:tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:121500  Loss:tensor(0.2608, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 47
loss: 0.17571130810352556
accuracy: 0.9368150177725119
Iteration:122000  Loss:tensor(0.1606, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:122500  Loss:tensor(0.2176, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:123000  Loss:tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:123500  Loss:tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:124000  Loss:tensor(0.0437, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 48
loss: 0.17505368726890047
accuracy: 0.9370556872037915
Iteration:124500  Loss:tensor(0.1095, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:125000  Loss:tensor(0.2066, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:125500  Loss:tensor(0.1275, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:126000  Loss:tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:126500  Loss:tensor(0.1433, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 49
loss: 0.17490406099620082
accuracy: 0.9371605943917851
Iteration:127000  Loss:tensor(0.2861, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:127500  Loss:tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:128000  Loss:tensor(0.1203, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:128500  Loss:tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:129000  Loss:tensor(0.1240, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 50
loss: 0.1730834632739719
accuracy: 0.9376851303317536
Iteration:129500  Loss:tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:130000  Loss:tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:130500  Loss:tensor(0.1730, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:131000  Loss:tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:131500  Loss:tensor(0.2071, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 51
loss: 0.18170667759924067
accuracy: 0.934864978278041
Iteration:132000  Loss:tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:132500  Loss:tensor(0.1044, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:133000  Loss:tensor(0.1811, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:133500  Loss:tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:134000  Loss:tensor(0.2223, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 52
loss: 0.17435500406407078
accuracy: 0.9375802231437599
Iteration:134500  Loss:tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:135000  Loss:tensor(0.2296, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:135500  Loss:tensor(0.1652, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:136000  Loss:tensor(0.1218, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:136500  Loss:tensor(0.1974, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 53
loss: 0.174975061236688
accuracy: 0.9368767278830964
Iteration:137000  Loss:tensor(0.1084, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:137500  Loss:tensor(0.0945, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:138000  Loss:tensor(0.1965, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:138500  Loss:tensor(0.1801, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:139000  Loss:tensor(0.1864, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 54
loss: 0.17461772167490203
accuracy: 0.9378640896524486
Iteration:139500  Loss:tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:140000  Loss:tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:140500  Loss:tensor(0.1564, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:141000  Loss:tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:141500  Loss:tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 55
loss: 0.1734420413263201
accuracy: 0.9380245359399684
Iteration:142000  Loss:tensor(0.1845, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:142500  Loss:tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:143000  Loss:tensor(0.2279, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:143500  Loss:tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:144000  Loss:tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 56
loss: 0.172138791152101
accuracy: 0.937555539099526
Iteration:144500  Loss:tensor(0.0616, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:145000  Loss:tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:145500  Loss:tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:146000  Loss:tensor(0.2317, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:146500  Loss:tensor(0.1688, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 57
loss: 0.16948021672545427
accuracy: 0.9393389612954186
Iteration:147000  Loss:tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:147500  Loss:tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:148000  Loss:tensor(0.1464, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:148500  Loss:tensor(0.1437, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:149000  Loss:tensor(0.2904, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 58
loss: 0.17005940327070665
accuracy: 0.9386971761453397
Iteration:149500  Loss:tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:150000  Loss:tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:150500  Loss:tensor(0.2478, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:151000  Loss:tensor(0.3085, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:151500  Loss:tensor(0.0504, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 59
loss: 0.17067232464350418
accuracy: 0.9385367298578199
Iteration:152000  Loss:tensor(0.1623, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:152500  Loss:tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:153000  Loss:tensor(0.2674, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:153500  Loss:tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:154000  Loss:tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 60
loss: 0.16662711632624858
accuracy: 0.9405114533965245
Iteration:154500  Loss:tensor(0.2666, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:155000  Loss:tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:155500  Loss:tensor(0.3888, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:156000  Loss:tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:156500  Loss:tensor(0.1583, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 61
loss: 0.16608855542896012
accuracy: 0.9409063981042654
Iteration:157000  Loss:tensor(0.2235, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:157500  Loss:tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:158000  Loss:tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:158500  Loss:tensor(0.1737, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:159000  Loss:tensor(0.3201, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:159500  Loss:tensor(0.1411, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 62
loss: 0.1661382772897975
accuracy: 0.940573163507109
Iteration:160000  Loss:tensor(0.2295, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:160500  Loss:tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:161000  Loss:tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:161500  Loss:tensor(0.1616, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:162000  Loss:tensor(0.1573, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 63
loss: 0.16786492367806194
accuracy: 0.9397647610584519
Iteration:162500  Loss:tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:163000  Loss:tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:163500  Loss:tensor(0.1401, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:164000  Loss:tensor(0.1323, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:164500  Loss:tensor(0.2748, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 64
loss: 0.16648502625844266
accuracy: 0.9408755430489731
Iteration:165000  Loss:tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:165500  Loss:tensor(0.1194, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:166000  Loss:tensor(0.1747, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:166500  Loss:tensor(0.2164, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:167000  Loss:tensor(0.3753, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 65
loss: 0.16628435340534903
accuracy: 0.9406225315955766
Iteration:167500  Loss:tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:168000  Loss:tensor(0.1085, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:168500  Loss:tensor(0.1669, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:169000  Loss:tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:169500  Loss:tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 66
loss: 0.16670379864852317
accuracy: 0.940708925750395
Iteration:170000  Loss:tensor(0.1075, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:170500  Loss:tensor(0.1996, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:171000  Loss:tensor(0.2184, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:171500  Loss:tensor(0.1094, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:172000  Loss:tensor(0.2409, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 67
loss: 0.1655582578765967
accuracy: 0.9406348736176935
Iteration:172500  Loss:tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:173000  Loss:tensor(0.1720, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:173500  Loss:tensor(0.1933, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:174000  Loss:tensor(0.2074, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:174500  Loss:tensor(0.2421, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 68
loss: 0.1657076997183687
accuracy: 0.9408076619273301
Iteration:175000  Loss:tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:175500  Loss:tensor(0.4059, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:176000  Loss:tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:176500  Loss:tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:177000  Loss:tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 69
loss: 0.16413828315534063
accuracy: 0.9407212677725119
Iteration:177500  Loss:tensor(0.2239, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:178000  Loss:tensor(0.1542, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:178500  Loss:tensor(0.1897, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:179000  Loss:tensor(0.2213, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:179500  Loss:tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 70
loss: 0.16572616831583412
accuracy: 0.9409619372037915
Iteration:180000  Loss:tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:180500  Loss:tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:181000  Loss:tensor(0.1062, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:181500  Loss:tensor(0.2520, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:182000  Loss:tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 71
loss: 0.16477435584567005
accuracy: 0.9408508590047393
Iteration:182500  Loss:tensor(0.2436, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:183000  Loss:tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:183500  Loss:tensor(0.1539, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:184000  Loss:tensor(0.1609, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:184500  Loss:tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 72
loss: 0.16568813610036298
accuracy: 0.9407336097946287
Iteration:185000  Loss:tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:185500  Loss:tensor(0.1426, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:186000  Loss:tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:186500  Loss:tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:187000  Loss:tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 73
loss: 0.16497853281319225
accuracy: 0.9410606733807267
Iteration:187500  Loss:tensor(0.1170, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:188000  Loss:tensor(0.1928, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:188500  Loss:tensor(0.1642, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:189000  Loss:tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:189500  Loss:tensor(0.1294, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 74
loss: 0.16421194024469357
accuracy: 0.9410791864139021
Iteration:190000  Loss:tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:190500  Loss:tensor(0.1658, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:191000  Loss:tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:191500  Loss:tensor(0.1192, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:192000  Loss:tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 75
loss: 0.16487064190307488
accuracy: 0.9406842417061612
Iteration:192500  Loss:tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:193000  Loss:tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:193500  Loss:tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:194000  Loss:tensor(0.1218, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:194500  Loss:tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 76
loss: 0.16496104637299197
accuracy: 0.9407768068720379
Iteration:195000  Loss:tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:195500  Loss:tensor(0.1215, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:196000  Loss:tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:196500  Loss:tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:197000  Loss:tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 77
loss: 0.1649993580234889
accuracy: 0.9406780706951027
Iteration:197500  Loss:tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:198000  Loss:tensor(0.2506, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:198500  Loss:tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:199000  Loss:tensor(0.0995, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:199500  Loss:tensor(0.2066, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:200000  Loss:tensor(0.2426, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 78
loss: 0.16458139695502277
accuracy: 0.9408755430489731
Iteration:200500  Loss:tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:201000  Loss:tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:201500  Loss:tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:202000  Loss:tensor(0.0902, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:202500  Loss:tensor(0.3358, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 79
loss: 0.16368761615192085
accuracy: 0.941202606635071
Iteration:203000  Loss:tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:203500  Loss:tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:204000  Loss:tensor(0.1329, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:204500  Loss:tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:205000  Loss:tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 80
loss: 0.16599282683064576
accuracy: 0.9409125691153238
Iteration:205500  Loss:tensor(0.2174, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:206000  Loss:tensor(0.1813, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:206500  Loss:tensor(0.2295, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:207000  Loss:tensor(0.0786, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:207500  Loss:tensor(0.3527, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 81
loss: 0.1655149892760414
accuracy: 0.9407829778830964
Iteration:208000  Loss:tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:208500  Loss:tensor(0.2460, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:209000  Loss:tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:209500  Loss:tensor(0.1087, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:210000  Loss:tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 82
loss: 0.16538612515772994
accuracy: 0.9410236473143759
Iteration:210500  Loss:tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:211000  Loss:tensor(0.1074, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:211500  Loss:tensor(0.2066, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:212000  Loss:tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:212500  Loss:tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 83
loss: 0.16437725784510115
accuracy: 0.9415296702211691
Iteration:213000  Loss:tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:213500  Loss:tensor(0.1961, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:214000  Loss:tensor(0.1539, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:214500  Loss:tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:215000  Loss:tensor(0.2946, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 84
loss: 0.16425500004986335
accuracy: 0.9411964356240127
Iteration:215500  Loss:tensor(0.1313, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:216000  Loss:tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:216500  Loss:tensor(0.0895, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:217000  Loss:tensor(0.1169, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:217500  Loss:tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 85
loss: 0.16533635927682028
accuracy: 0.9404003751974723
Iteration:218000  Loss:tensor(0.1554, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:218500  Loss:tensor(0.2520, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:219000  Loss:tensor(0.1332, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:219500  Loss:tensor(0.1750, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:220000  Loss:tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 86
loss: 0.16465658629695645
accuracy: 0.9411840936018957
Iteration:220500  Loss:tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:221000  Loss:tensor(0.1367, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:221500  Loss:tensor(0.1702, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:222000  Loss:tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:222500  Loss:tensor(0.1465, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 87
loss: 0.16389891478243337
accuracy: 0.9412828297788309
Iteration:223000  Loss:tensor(0.1464, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:223500  Loss:tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:224000  Loss:tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:224500  Loss:tensor(0.2637, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:225000  Loss:tensor(0.2570, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 88
loss: 0.16440126059376775
accuracy: 0.9411779225908373
Iteration:225500  Loss:tensor(0.2225, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:226000  Loss:tensor(0.1696, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:226500  Loss:tensor(0.3400, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:227000  Loss:tensor(0.1705, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:227500  Loss:tensor(0.1412, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 89
loss: 0.1627424866057444
accuracy: 0.9417024585308057
Iteration:228000  Loss:tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:228500  Loss:tensor(0.1764, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:229000  Loss:tensor(0.2514, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:229500  Loss:tensor(0.1892, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:230000  Loss:tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 90
loss: 0.16301915428776287
accuracy: 0.9415111571879937
Iteration:230500  Loss:tensor(0.1114, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:231000  Loss:tensor(0.1820, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:231500  Loss:tensor(0.2214, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:232000  Loss:tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:232500  Loss:tensor(0.1577, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 91
loss: 0.1634464728878443
accuracy: 0.9414432760663507
Iteration:233000  Loss:tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:233500  Loss:tensor(0.2413, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:234000  Loss:tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:234500  Loss:tensor(0.0704, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:235000  Loss:tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 92
loss: 0.16415733956227205
accuracy: 0.941474131121643
Iteration:235500  Loss:tensor(0.3795, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:236000  Loss:tensor(0.1959, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:236500  Loss:tensor(0.1648, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:237000  Loss:tensor(0.1753, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:237500  Loss:tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:238000  Loss:tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 93
loss: 0.16324382329412618
accuracy: 0.9414864731437599
Iteration:238500  Loss:tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:239000  Loss:tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:239500  Loss:tensor(0.1263, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:240000  Loss:tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:240500  Loss:tensor(0.2946, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 94
loss: 0.16251479717792494
accuracy: 0.9420110090837283
Iteration:241000  Loss:tensor(0.1289, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:241500  Loss:tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:242000  Loss:tensor(0.1724, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:242500  Loss:tensor(0.2567, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:243000  Loss:tensor(0.2831, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 95
loss: 0.16269179953682997
accuracy: 0.9416839454976303
Iteration:243500  Loss:tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:244000  Loss:tensor(0.1303, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:244500  Loss:tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:245000  Loss:tensor(0.1410, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:245500  Loss:tensor(0.1635, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 96
loss: 0.1632606056699085
accuracy: 0.9412951718009479
Iteration:246000  Loss:tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:246500  Loss:tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:247000  Loss:tensor(0.1965, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:247500  Loss:tensor(0.2447, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:248000  Loss:tensor(0.1872, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 97
loss: 0.16390773804422826
accuracy: 0.9411285545023697
Iteration:248500  Loss:tensor(0.1110, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:249000  Loss:tensor(0.2158, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:249500  Loss:tensor(0.2006, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:250000  Loss:tensor(0.1158, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:250500  Loss:tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 98
loss: 0.16362150423346444
accuracy: 0.9414864731437599
Iteration:251000  Loss:tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:251500  Loss:tensor(0.1164, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:252000  Loss:tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:252500  Loss:tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:253000  Loss:tensor(0.1345, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 99
loss: 0.16370429818799476
accuracy: 0.9415790383096366
Iteration:253500  Loss:tensor(0.1356, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:254000  Loss:tensor(0.0829, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:254500  Loss:tensor(0.3416, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:255000  Loss:tensor(0.2016, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:255500  Loss:tensor(0.1659, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 100
loss: 0.16339299378116243
accuracy: 0.9413692239336493
Iteration:256000  Loss:tensor(0.1338, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:256500  Loss:tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:257000  Loss:tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:257500  Loss:tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:258000  Loss:tensor(0.2305, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 101
loss: 0.16330889038893132
accuracy: 0.9414556180884676
Iteration:258500  Loss:tensor(0.1706, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:259000  Loss:tensor(0.0892, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:259500  Loss:tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:260000  Loss:tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:260500  Loss:tensor(0.2927, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 102
loss: 0.16380149149115228
accuracy: 0.9417765106635071
Iteration:261000  Loss:tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:261500  Loss:tensor(0.1378, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:262000  Loss:tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:262500  Loss:tensor(0.1133, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:263000  Loss:tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 103
loss: 0.16476194753928042
accuracy: 0.9408508590047393
Iteration:263500  Loss:tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:264000  Loss:tensor(0.1724, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:264500  Loss:tensor(0.1554, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:265000  Loss:tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:265500  Loss:tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 104
loss: 0.16400701704907333
accuracy: 0.9414000789889415
Iteration:266000  Loss:tensor(0.1114, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:266500  Loss:tensor(0.2050, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:267000  Loss:tensor(0.0858, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:267500  Loss:tensor(0.1934, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:268000  Loss:tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 105
loss: 0.164053858434752
accuracy: 0.9416160643759873
Iteration:268500  Loss:tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:269000  Loss:tensor(0.1897, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:269500  Loss:tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:270000  Loss:tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:270500  Loss:tensor(0.1134, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 106
loss: 0.16158508265017285
accuracy: 0.9421591133491312
Iteration:271000  Loss:tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:271500  Loss:tensor(0.2205, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:272000  Loss:tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:272500  Loss:tensor(0.2188, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:273000  Loss:tensor(0.1740, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 107
loss: 0.16298560988772984
accuracy: 0.941461789099526
Iteration:273500  Loss:tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:274000  Loss:tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:274500  Loss:tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:275000  Loss:tensor(0.2403, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:275500  Loss:tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 108
loss: 0.16387730409975323
accuracy: 0.9416160643759873
Iteration:276000  Loss:tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:276500  Loss:tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:277000  Loss:tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:277500  Loss:tensor(0.2616, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:278000  Loss:tensor(0.1381, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:278500  Loss:tensor(0.1896, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 109
loss: 0.16412309594717212
accuracy: 0.9415111571879937
Iteration:279000  Loss:tensor(0.2007, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:279500  Loss:tensor(0.1304, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:280000  Loss:tensor(0.1759, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:280500  Loss:tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:281000  Loss:tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 110
loss: 0.16297474512749455
accuracy: 0.941665432464455
Iteration:281500  Loss:tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:282000  Loss:tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:282500  Loss:tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:283000  Loss:tensor(0.1855, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:283500  Loss:tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 111
loss: 0.16362618145902197
accuracy: 0.9416284063981043
Iteration:284000  Loss:tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:284500  Loss:tensor(0.1346, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:285000  Loss:tensor(0.1448, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:285500  Loss:tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:286000  Loss:tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 112
loss: 0.16387045809279652
accuracy: 0.9417765106635071
Iteration:286500  Loss:tensor(0.1837, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:287000  Loss:tensor(0.2511, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:287500  Loss:tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:288000  Loss:tensor(0.1216, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:288500  Loss:tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 113
loss: 0.16343422889000314
accuracy: 0.9415728672985783
Iteration:289000  Loss:tensor(0.3827, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:289500  Loss:tensor(0.2877, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:290000  Loss:tensor(0.0957, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:290500  Loss:tensor(0.1455, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:291000  Loss:tensor(0.1642, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 114
loss: 0.1630338622296838
accuracy: 0.9416037223538705
Iteration:291500  Loss:tensor(0.1237, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:292000  Loss:tensor(0.2150, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:292500  Loss:tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:293000  Loss:tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:293500  Loss:tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 115
loss: 0.16336582296808938
accuracy: 0.9416839454976303
Iteration:294000  Loss:tensor(0.0824, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:294500  Loss:tensor(0.1137, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:295000  Loss:tensor(0.0989, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:295500  Loss:tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:296000  Loss:tensor(0.1370, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 116
loss: 0.16467228804687023
accuracy: 0.941474131121643
Iteration:296500  Loss:tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:297000  Loss:tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:297500  Loss:tensor(0.2286, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:298000  Loss:tensor(0.0616, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:298500  Loss:tensor(0.0724, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 117
loss: 0.16423219767852287
accuracy: 0.9413568819115324
Iteration:299000  Loss:tensor(0.0796, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:299500  Loss:tensor(0.1379, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:300000  Loss:tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:300500  Loss:tensor(0.2192, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:301000  Loss:tensor(0.1562, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 118
loss: 0.16246086451641356
accuracy: 0.9422269944707741
Iteration:301500  Loss:tensor(0.3441, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:302000  Loss:tensor(0.3472, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:302500  Loss:tensor(0.1622, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:303000  Loss:tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:303500  Loss:tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 119
loss: 0.16413205228253058
accuracy: 0.9408693720379147
Iteration:304000  Loss:tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:304500  Loss:tensor(0.1900, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:305000  Loss:tensor(0.1510, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:305500  Loss:tensor(0.2130, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:306000  Loss:tensor(0.0925, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 120
loss: 0.16375351519843248
accuracy: 0.9413013428120063
Iteration:306500  Loss:tensor(0.1091, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:307000  Loss:tensor(0.1340, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:307500  Loss:tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:308000  Loss:tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:308500  Loss:tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 121
loss: 0.16301143036987545
accuracy: 0.941202606635071
Iteration:309000  Loss:tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:309500  Loss:tensor(0.1974, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:310000  Loss:tensor(0.1350, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:310500  Loss:tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:311000  Loss:tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 122
loss: 0.16221279617969836
accuracy: 0.9420356931279621
Iteration:311500  Loss:tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:312000  Loss:tensor(0.3532, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:312500  Loss:tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:313000  Loss:tensor(0.1899, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:313500  Loss:tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 123
loss: 0.16282458535188113
accuracy: 0.9415605252764613
Iteration:314000  Loss:tensor(0.1459, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:314500  Loss:tensor(0.1433, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:315000  Loss:tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:315500  Loss:tensor(0.1149, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:316000  Loss:tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:316500  Loss:tensor(0.3341, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 124
loss: 0.1634728186289334
accuracy: 0.9418505627962085
Iteration:317000  Loss:tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:317500  Loss:tensor(0.1156, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:318000  Loss:tensor(0.2520, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:318500  Loss:tensor(0.1684, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:319000  Loss:tensor(0.1764, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 125
loss: 0.1624681071089919
accuracy: 0.9421097452606635
Iteration:319500  Loss:tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:320000  Loss:tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
Iteration:320500  Loss:tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:321000  Loss:tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:321500  Loss:tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(86, device='cuda:0')
echo: 126
loss: 0.1634013229590439
accuracy: 0.9417703396524486
Iteration:322000  Loss:tensor(0.2812, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:322500  Loss:tensor(0.1832, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:323000  Loss:tensor(0.1300, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:323500  Loss:tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
Iteration:324000  Loss:tensor(0.2514, device='cuda:0', grad_fn=<NllLossBackward>)  Accuracy:tensor(87, device='cuda:0')
echo: 127
loss: 0.1635202866700135
accuracy: 0.9417271425750395
